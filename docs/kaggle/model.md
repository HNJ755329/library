# モデル

## 最近傍法

小さいデータに関してはよいベースラインとなる．説明が用意．

## 線形モデル

最初に試してみるべきアルゴリズム.非常に大きいデータセットに適する.非常に高次元のデータに適する.

## ナイーブベイズ
クラス分類にしか使えない.線形モデルよりもさらに高速.非常に大きいデータセット、高次元データに適する.線形モデルより精度が劣ることが多い.

## 決定木

非常に高速.データのスケールを考慮する必要がない.可視化が可能で説明しやすい.

## ランダムフォレスト

ほとんどの場合単一の決定木よりも高速で、頑健で、強力.データのスケールを考慮する必要がない.高次元の疎なデータには適さない.

## 勾配ブースティング決定木

多くの場合ランダムフォレストよりも少し精度が高い.ランダムフオレストよりも訓練に時間がかかるが、予測はこちらのほうが速く、 メモリ使用量も小さい.ランダムフオレストよりもパラメータに敏感.

## サポートベクタマシン
同じような意味を持つ特徴量からなる中規模なデータセットに対しては強力.データのスケールを調整する必要がある.パラメータに敏感.

## ニューラルネットワーク
非常に複雑なモデルを構築できる.特に大きなデータセットに有効.データのスケールを調整する必要がある.パラメータに敏感.大きいモデルは訓練に時間がかかる.
# 線形モデル

```python
from sklearn.linear_model import (
    LinearRegression,
    Ridge,
    Lasso
)
```

## 線形回帰

過剰適合

## リッジ回帰

L2正規化
制約の強いモデルなので過剰適合はすくない．
Ridgeモデルでは,モデルの簡潔さと訓練セットに対する性能がトレードオプの関係になる．どちらに重きを置くかはalphaパラメーターを用いて指定することができる．

## Lasso回帰

L1正規化．
いくつかの係数が完全に０になる．これはモデルにおける特徴量が完全に無視されるということになる．
自動的に特徴量を選択していると考えてもよい．いくつかの係数が０になると,モデルを解釈しやすくなり,どの特徴量が重要なのかが明らかになる．
より解釈しやすいモデル．